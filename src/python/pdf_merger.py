#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„PDFåˆå¹¶æœåŠ¡ç±»
æ”¯æŒæµå¼å¤„ç†ã€å†…å­˜ä¼˜åŒ–å’Œä¼ä¸šçº§é”™è¯¯å¤„ç†
"""

import os
import sys
import json
import logging
import fitz  # PyMuPDF
from datetime import datetime
from urllib.parse import urlparse
from typing import Dict, List, Optional, Callable, Any
import gc
import psutil
import time

class PDFMergerError(Exception):
    """PDFåˆå¹¶ç›¸å…³å¼‚å¸¸"""
    pass

class ConfigurationError(PDFMergerError):
    """é…ç½®é”™è¯¯å¼‚å¸¸"""
    pass

class FileProcessingError(PDFMergerError):
    """æ–‡ä»¶å¤„ç†å¼‚å¸¸"""
    pass

class PDFMerger:
    """
    ä¼ä¸šçº§PDFåˆå¹¶æœåŠ¡ç±»
    
    ç‰¹æ€§ï¼š
    - æµå¼å¤„ç†ï¼Œé¿å…å†…å­˜æº¢å‡º
    - å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶
    - è¿›åº¦è·Ÿè¸ªå’Œæ€§èƒ½ç›‘æ§
    - é…ç½®é©±åŠ¨å’Œçµæ´»æ‰©å±•
    - å†…å­˜ä½¿ç”¨ä¼˜åŒ–
    """
    
    def __init__(self, config_path: str = 'config.json', logger: Optional[logging.Logger] = None):
        """
        åˆå§‹åŒ–PDFåˆå¹¶å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            logger: å¯é€‰çš„æ—¥å¿—è®°å½•å™¨
        """
        self.config_path = config_path
        self.logger = logger or self._setup_logger()
        
        # åŠ è½½é…ç½®
        self.config = self._load_config(config_path)
        
        # è®¾ç½®è·¯å¾„
        self.pdf_dir = self.config['pdfDir']
        self.metadata_dir = os.path.join(
            self.pdf_dir, 
            self.config.get('metadata', {}).get('directory', 'metadata')
        )
        self.final_pdf_dir = os.path.join(
            self.pdf_dir, 
            self.config.get('output', {}).get('finalPdfDirectory', 'finalPdf')
        )
        
        # æ€§èƒ½ç›‘æ§
        self.stats = {
            'files_processed': 0,
            'total_pages': 0,
            'start_time': None,
            'memory_peak': 0,
            'errors': []
        }
        
        # åŠ è½½æ–‡ç« æ ‡é¢˜
        self.article_titles = self._load_article_titles()
        
        self.logger.info(f"PDFåˆå¹¶å™¨åˆå§‹åŒ–å®Œæˆ - PDFç›®å½•: {self.pdf_dir}")

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®é»˜è®¤æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger('PDFMerger')
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """
        åŠ è½½é…ç½®æ–‡ä»¶
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            é…ç½®å­—å…¸
            
        Raises:
            ConfigurationError: é…ç½®åŠ è½½å¤±è´¥
        """
        try:
            if not os.path.exists(config_path):
                raise ConfigurationError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # éªŒè¯å¿…éœ€çš„é…ç½®é¡¹
            required_keys = ['rootURL', 'pdfDir']
            for key in required_keys:
                if key not in config:
                    raise ConfigurationError(f"ç¼ºå°‘å¿…éœ€çš„é…ç½®é¡¹: {key}")
            
            return config
            
        except json.JSONDecodeError as e:
            raise ConfigurationError(f"é…ç½®æ–‡ä»¶JSONæ ¼å¼é”™è¯¯: {e}")
        except Exception as e:
            raise ConfigurationError(f"é…ç½®åŠ è½½å¤±è´¥: {e}")

    def _load_article_titles(self) -> Dict[str, str]:
        """
        åŠ è½½æ–‡ç« æ ‡é¢˜æ˜ å°„
        
        Returns:
            æ–‡ç« æ ‡é¢˜å­—å…¸
        """
        article_titles = {}
        
        try:
            # å°è¯•ä»å…ƒæ•°æ®ç›®å½•åŠ è½½
            metadata_file = os.path.join(self.metadata_dir, 'articleTitles.json')
            if os.path.exists(metadata_file):
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    article_titles = json.load(f)
                    self.logger.info(f"ä»å…ƒæ•°æ®ç›®å½•åŠ è½½äº† {len(article_titles)} ä¸ªæ–‡ç« æ ‡é¢˜")
            
            # å›é€€åˆ°PDFç›®å½•
            if not article_titles:
                fallback_file = os.path.join(self.pdf_dir, 'articleTitles.json')
                if os.path.exists(fallback_file):
                    with open(fallback_file, 'r', encoding='utf-8') as f:
                        article_titles = json.load(f)
                        self.logger.info(f"ä»PDFç›®å½•åŠ è½½äº† {len(article_titles)} ä¸ªæ–‡ç« æ ‡é¢˜")
                        
        except Exception as e:
            self.logger.warning(f"åŠ è½½æ–‡ç« æ ‡é¢˜å¤±è´¥: {e}")
        
        return article_titles

    def _get_pdf_files(self, directory_path: str) -> List[str]:
        """
        è·å–ç›®å½•ä¸­çš„PDFæ–‡ä»¶åˆ—è¡¨ï¼ˆå·²æ’åºï¼‰
        
        Args:
            directory_path: ç›®å½•è·¯å¾„
            
        Returns:
            æ’åºåçš„PDFæ–‡ä»¶åˆ—è¡¨
        """
        try:
            if not os.path.exists(directory_path):
                self.logger.warning(f"ç›®å½•ä¸å­˜åœ¨: {directory_path}")
                return []
            
            files = [
                f for f in os.listdir(directory_path) 
                if f.endswith('.pdf') and os.path.isfile(os.path.join(directory_path, f))
            ]
            
            # æŒ‰æ•°å­—å‰ç¼€æ’åº
            def get_sort_key(filename: str) -> int:
                try:
                    return int(filename.split('-')[0])
                except (ValueError, IndexError):
                    return 999999  # å°†æ— æ•ˆæ ¼å¼çš„æ–‡ä»¶æ’åˆ°æœ€å
            
            files.sort(key=get_sort_key)
            
            self.logger.info(f"æ‰¾åˆ° {len(files)} ä¸ªPDFæ–‡ä»¶åœ¨ {directory_path}")
            return files
            
        except Exception as e:
            self.logger.error(f"è·å–PDFæ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def _create_bookmark_title(self, filename: str, article_titles: Dict[str, str]) -> str:
        """
        åˆ›å»ºä¹¦ç­¾æ ‡é¢˜
        
        Args:
            filename: æ–‡ä»¶å
            article_titles: æ–‡ç« æ ‡é¢˜æ˜ å°„
            
        Returns:
            ä¹¦ç­¾æ ‡é¢˜
        """
        try:
            # æå–æ•°å­—å‰ç¼€
            parts = filename.split('-')
            if len(parts) < 2:
                return os.path.splitext(filename)[0]
            
            number_prefix = parts[0]
            
            # æŸ¥æ‰¾æ–‡ç« æ ‡é¢˜
            article_title = article_titles.get(number_prefix, '')
            if article_title:
                return article_title
            
            # å›é€€åˆ°æ¸…ç†åçš„æ–‡ä»¶å
            cleaned_name = '-'.join(parts[1:])
            return os.path.splitext(cleaned_name)[0]
            
        except Exception as e:
            self.logger.warning(f"åˆ›å»ºä¹¦ç­¾æ ‡é¢˜å¤±è´¥ {filename}: {e}")
            return os.path.splitext(filename)[0]

    def _monitor_memory(self) -> None:
        """ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        try:
            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            self.stats['memory_peak'] = max(self.stats['memory_peak'], memory_mb)
            
            # å¦‚æœå†…å­˜ä½¿ç”¨è¶…è¿‡é˜ˆå€¼ï¼Œå¼ºåˆ¶åƒåœ¾å›æ”¶
            if memory_mb > 500:  # 500MBé˜ˆå€¼
                gc.collect()
                self.logger.debug(f"å†…å­˜ä½¿ç”¨: {memory_mb:.1f}MB, å·²æ‰§è¡Œåƒåœ¾å›æ”¶")
        except Exception:
            pass  # å†…å­˜ç›‘æ§å¤±è´¥ä¸åº”å½±å“ä¸»æµç¨‹

    def merge_pdfs_stream(
        self, 
        directory_path: str, 
        output_path: str, 
        progress_callback: Optional[Callable[[int, int], None]] = None
    ) -> bool:
        """
        æµå¼åˆå¹¶PDFæ–‡ä»¶
        
        Args:
            directory_path: æºç›®å½•è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            åˆå¹¶æ˜¯å¦æˆåŠŸ
            
        Raises:
            FileProcessingError: æ–‡ä»¶å¤„ç†é”™è¯¯
        """
        files = self._get_pdf_files(directory_path)
        if not files:
            self.logger.warning(f"ç›®å½•ä¸­æ²¡æœ‰PDFæ–‡ä»¶: {directory_path}")
            return False

        merged_pdf = None
        current_file_pdf = None
        
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            merged_pdf = fitz.open()  # åˆ›å»ºç©ºçš„PDFæ–‡æ¡£
            toc = []  # ç›®å½•ç»“æ„
            
            self.logger.info(f"å¼€å§‹åˆå¹¶ {len(files)} ä¸ªPDFæ–‡ä»¶åˆ° {output_path}")
            
            for i, filename in enumerate(files):
                try:
                    file_path = os.path.join(directory_path, filename)
                    
                    # æ‰“å¼€å½“å‰PDFæ–‡ä»¶
                    current_file_pdf = fitz.open(file_path)
                    page_count = current_file_pdf.page_count
                    
                    if page_count == 0:
                        self.logger.warning(f"è·³è¿‡ç©ºPDFæ–‡ä»¶: {filename}")
                        current_file_pdf.close()
                        continue
                    
                    # è®°å½•åˆå¹¶å‰çš„é¡µæ•°
                    start_page = merged_pdf.page_count
                    
                    # æ’å…¥PDFé¡µé¢
                    merged_pdf.insert_pdf(current_file_pdf)
                    
                    # åˆ›å»ºä¹¦ç­¾
                    bookmark_title = self._create_bookmark_title(filename, self.article_titles)
                    toc.append([
                        1,  # çº§åˆ«
                        bookmark_title,  # æ ‡é¢˜
                        start_page + 1,  # é¡µç ï¼ˆä»1å¼€å§‹ï¼‰
                        {"kind": 1, "page": start_page}  # é“¾æ¥ä¿¡æ¯
                    ])
                    
                    # å…³é—­å½“å‰æ–‡ä»¶
                    current_file_pdf.close()
                    current_file_pdf = None
                    
                    # æ›´æ–°ç»Ÿè®¡
                    self.stats['files_processed'] += 1
                    self.stats['total_pages'] += page_count
                    
                    # å†…å­˜ç›‘æ§
                    self._monitor_memory()
                    
                    # è¿›åº¦å›è°ƒ
                    if progress_callback:
                        progress_callback(i + 1, len(files))
                    
                    self.logger.debug(f"å·²åˆå¹¶: {filename} ({page_count} é¡µ)")
                    
                except Exception as e:
                    error_msg = f"å¤„ç†æ–‡ä»¶å¤±è´¥ {filename}: {e}"
                    self.logger.error(error_msg)
                    self.stats['errors'].append(error_msg)
                    
                    if current_file_pdf:
                        current_file_pdf.close()
                        current_file_pdf = None
                    
                    # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶
                    continue
            
            # è®¾ç½®ç›®å½•ç»“æ„
            if toc:
                merged_pdf.set_toc(toc)
                self.logger.info(f"è®¾ç½®äº† {len(toc)} ä¸ªä¹¦ç­¾")
            
            # ä¿å­˜åˆå¹¶åçš„PDF
            merged_pdf.save(output_path)
            self.logger.info(f"PDFåˆå¹¶å®Œæˆ: {output_path}")
            
            return True
            
        except Exception as e:
            error_msg = f"PDFåˆå¹¶å¤±è´¥: {e}"
            self.logger.error(error_msg)
            self.stats['errors'].append(error_msg)
            raise FileProcessingError(error_msg)
            
        finally:
            # æ¸…ç†èµ„æº
            if current_file_pdf:
                current_file_pdf.close()
            if merged_pdf:
                merged_pdf.close()
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()

    def merge_directory(self, directory_name: Optional[str] = None) -> List[str]:
        """
        åˆå¹¶æŒ‡å®šç›®å½•æˆ–æ‰€æœ‰å­ç›®å½•çš„PDFæ–‡ä»¶
        
        Args:
            directory_name: ç›®å½•åï¼ˆNoneè¡¨ç¤ºåˆå¹¶æ‰€æœ‰ï¼‰
            
        Returns:
            æˆåŠŸåˆå¹¶çš„æ–‡ä»¶åˆ—è¡¨
        """
        if not os.path.exists(self.pdf_dir):
            raise FileProcessingError(f"PDFç›®å½•ä¸å­˜åœ¨: {self.pdf_dir}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.final_pdf_dir, exist_ok=True)
        
        # è·å–åŸŸåå’Œæ—¥æœŸ
        url = urlparse(self.config['rootURL'])
        domain = url.hostname.replace('.', '_') if url.hostname else 'unknown'
        current_date = datetime.now().strftime('%Y%m%d')
        
        merged_files = []
        
        try:
            if directory_name:
                # åˆå¹¶æŒ‡å®šç›®å½•
                directory_path = os.path.join(self.pdf_dir, directory_name)
                if os.path.isdir(directory_path):
                    output_path = os.path.join(
                        self.final_pdf_dir, 
                        f"{directory_name}_{current_date}.pdf"
                    )
                    
                    if self.merge_pdfs_stream(directory_path, output_path):
                        merged_files.append(output_path)
                else:
                    self.logger.warning(f"æŒ‡å®šç›®å½•ä¸å­˜åœ¨: {directory_path}")
            else:
                # é¦–å…ˆåˆå¹¶æ ¹ç›®å½•
                root_output_path = os.path.join(
                    self.final_pdf_dir, 
                    f"{domain}_{current_date}.pdf"
                )
                
                if self.merge_pdfs_stream(self.pdf_dir, root_output_path):
                    merged_files.append(root_output_path)
                
                # ç„¶ååˆå¹¶æ‰€æœ‰å­ç›®å½•
                for item in os.listdir(self.pdf_dir):
                    item_path = os.path.join(self.pdf_dir, item)
                    
                    # è·³è¿‡éç›®å½•å’Œç‰¹æ®Šç›®å½•
                    if not os.path.isdir(item_path) or item in ['finalPdf', 'metadata', '.temp']:
                        continue
                    
                    output_path = os.path.join(
                        self.final_pdf_dir, 
                        f"{item}_{current_date}.pdf"
                    )
                    
                    if self.merge_pdfs_stream(item_path, output_path):
                        merged_files.append(output_path)
            
            return merged_files
            
        except Exception as e:
            error_msg = f"ç›®å½•åˆå¹¶å¤±è´¥: {e}"
            self.logger.error(error_msg)
            raise FileProcessingError(error_msg)

    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–åˆå¹¶ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        elapsed_time = 0
        if self.stats['start_time']:
            elapsed_time = time.time() - self.stats['start_time']
        
        return {
            'files_processed': self.stats['files_processed'],
            'total_pages': self.stats['total_pages'],
            'elapsed_time': elapsed_time,
            'memory_peak_mb': self.stats['memory_peak'],
            'errors_count': len(self.stats['errors']),
            'errors': self.stats['errors'][-10],  # æœ€è¿‘10ä¸ªé”™è¯¯
            'avg_pages_per_file': (
                self.stats['total_pages'] / self.stats['files_processed'] 
                if self.stats['files_processed'] > 0 else 0
            ),
            'processing_speed': (
                self.stats['files_processed'] / elapsed_time 
                if elapsed_time > 0 else 0
            )
        }

    def run(self) -> Dict[str, Any]:
        """
        è¿è¡ŒPDFåˆå¹¶ä»»åŠ¡
        
        Returns:
            æ‰§è¡Œç»“æœå’Œç»Ÿè®¡ä¿¡æ¯
        """
        self.stats['start_time'] = time.time()
        self.logger.info("å¼€å§‹PDFåˆå¹¶ä»»åŠ¡")
        
        try:
            # æ‰§è¡Œåˆå¹¶
            merged_files = self.merge_directory()
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = self.get_statistics()
            
            result = {
                'success': True,
                'merged_files': merged_files,
                'statistics': stats
            }
            
            self.logger.info(f"PDFåˆå¹¶ä»»åŠ¡å®Œæˆ: å¤„ç†äº† {stats['files_processed']} ä¸ªæ–‡ä»¶, "
                           f"å…± {stats['total_pages']} é¡µ, "
                           f"ç”¨æ—¶ {stats['elapsed_time']:.1f} ç§’")
            
            return result
            
        except Exception as e:
            error_msg = f"PDFåˆå¹¶ä»»åŠ¡å¤±è´¥: {e}"
            self.logger.error(error_msg)
            
            return {
                'success': False,
                'error': error_msg,
                'statistics': self.get_statistics()
            }

def main():
    """ä¸»å‡½æ•°ï¼Œæ”¯æŒå‘½ä»¤è¡Œæ‰§è¡Œ"""
    import sys
    import argparse
    
    parser = argparse.ArgumentParser(description='PDFåˆå¹¶å·¥å…·')
    parser.add_argument('--config', default='config.json', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--directory', help='æŒ‡å®šè¦åˆå¹¶çš„ç›®å½•å')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)
    
    try:
        # åˆ›å»ºPDFåˆå¹¶å™¨
        merger = PDFMerger(config_path=args.config)
        
        # æ‰§è¡Œåˆå¹¶
        if args.directory:
            merged_files = merger.merge_directory(args.directory)
        else:
            result = merger.run()
            merged_files = result.get('merged_files', [])
        
        # è¾“å‡ºç»“æœ
        print(f"\nâœ… åˆå¹¶å®Œæˆ! ç”Ÿæˆäº† {len(merged_files)} ä¸ªPDFæ–‡ä»¶:")
        for file_path in merged_files:
            print(f"  ğŸ“„ {file_path}")
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        stats = merger.get_statistics()
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  - å¤„ç†æ–‡ä»¶æ•°: {stats['files_processed']}")
        print(f"  - æ€»é¡µæ•°: {stats['total_pages']}")
        print(f"  - ç”¨æ—¶: {stats['elapsed_time']:.1f} ç§’")
        print(f"  - å†…å­˜å³°å€¼: {stats['memory_peak_mb']:.1f} MB")
        
        if stats['errors_count'] > 0:
            print(f"  âš ï¸  é”™è¯¯æ•°: {stats['errors_count']}")
        
        return 0
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}", file=sys.stderr)
        return 1

if __name__ == '__main__':
    sys.exit(main())