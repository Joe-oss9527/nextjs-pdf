#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„PDFåˆå¹¶æœåŠ¡ç±» - ä¿®å¤æ–‡ä»¶æ’åºæ”¯æŒæ•°å­—ç´¢å¼•
"""

import os
import sys
import json
import logging
import fitz  # PyMuPDF
from datetime import datetime
from urllib.parse import urlparse
from typing import Dict, List, Optional, Callable, Any
import gc
import psutil
import time
import traceback

class PDFMergerError(Exception):
    """PDFåˆå¹¶ç›¸å…³å¼‚å¸¸"""
    pass

class ConfigurationError(PDFMergerError):
    """é…ç½®é”™è¯¯å¼‚å¸¸"""
    pass

class FileProcessingError(PDFMergerError):
    """æ–‡ä»¶å¤„ç†å¼‚å¸¸"""
    pass

class PDFMerger:
    """
    ä¼ä¸šçº§PDFåˆå¹¶æœåŠ¡ç±» - æ™ºèƒ½æ’åºç‰ˆæœ¬

    ç‰¹æ€§ï¼š
    - æ™ºèƒ½æ–‡ä»¶æ’åºï¼ˆæ”¯æŒæ•°å­—ç´¢å¼•å’Œå“ˆå¸Œå‰ç¼€ï¼‰
    - æµå¼å¤„ç†ï¼Œé¿å…å†…å­˜æº¢å‡º
    - å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶
    - è¿›åº¦è·Ÿè¸ªå’Œæ€§èƒ½ç›‘æ§
    """

    def __init__(self, config_path: str = 'config.json', logger: Optional[logging.Logger] = None):
        """
        åˆå§‹åŒ–PDFåˆå¹¶å™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            logger: å¯é€‰çš„æ—¥å¿—è®°å½•å™¨
        """
        self.config_path = config_path
        self.logger = logger or self._setup_logger()

        # åŠ è½½é…ç½®
        self.config = self._load_config(config_path)

        # è®¾ç½®è·¯å¾„
        self.pdf_dir = self.config['pdfDir']
        self.metadata_dir = os.path.join(
            self.pdf_dir,
            self.config.get('metadata', {}).get('directory', 'metadata')
        )
        self.final_pdf_dir = os.path.join(
            self.pdf_dir,
            self.config.get('output', {}).get('finalPdfDirectory', 'finalPdf')
        )

        # æ€§èƒ½ç›‘æ§
        self.stats = {
            'files_processed': 0,
            'total_pages': 0,
            'start_time': None,
            'memory_peak': 0,
            'errors': []
        }

        # åŠ è½½æ–‡ç« æ ‡é¢˜
        self.article_titles = self._load_article_titles()

        # åŠ è½½sectionç»“æ„ï¼ˆç”¨äºåˆ†å±‚TOCï¼‰
        self.section_structure = self._load_section_structure()

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®é»˜è®¤æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger('PDFMerger')
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.WARNING)  # Only show warnings and errors
        return logger

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            if not os.path.exists(config_path):
                raise ConfigurationError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")

            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)

            # éªŒè¯å¿…éœ€çš„é…ç½®é¡¹
            required_keys = ['rootURL', 'pdfDir']
            for key in required_keys:
                if key not in config:
                    raise ConfigurationError(f"ç¼ºå°‘å¿…éœ€çš„é…ç½®é¡¹: {key}")

            return config

        except json.JSONDecodeError as e:
            raise ConfigurationError(f"é…ç½®æ–‡ä»¶JSONæ ¼å¼é”™è¯¯: {e}")
        except Exception as e:
            raise ConfigurationError(f"é…ç½®åŠ è½½å¤±è´¥: {e}")

    def _load_article_titles(self) -> Dict[str, str]:
        """åŠ è½½æ–‡ç« æ ‡é¢˜æ˜ å°„"""
        article_titles = {}

        try:
            # å°è¯•ä»å…ƒæ•°æ®ç›®å½•åŠ è½½
            metadata_file = os.path.join(self.metadata_dir, 'articleTitles.json')
            if os.path.exists(metadata_file):
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    article_titles = json.load(f)
                    pass  # Loaded article titles from metadata

            # å›é€€åˆ°PDFç›®å½•
            if not article_titles:
                fallback_file = os.path.join(self.pdf_dir, 'articleTitles.json')
                if os.path.exists(fallback_file):
                    with open(fallback_file, 'r', encoding='utf-8') as f:
                        article_titles = json.load(f)
                        pass  # Loaded article titles from PDF directory

        except Exception as e:
            self.logger.warning(f"åŠ è½½æ–‡ç« æ ‡é¢˜å¤±è´¥: {e}")

        return article_titles

    def _load_section_structure(self) -> Optional[Dict[str, Any]]:
        """åŠ è½½sectionç»“æ„ä¿¡æ¯ï¼ˆç”¨äºåˆ†å±‚TOCï¼‰"""
        section_structure = None

        try:
            # å°è¯•ä»å…ƒæ•°æ®ç›®å½•åŠ è½½
            metadata_file = os.path.join(self.metadata_dir, 'sectionStructure.json')
            if os.path.exists(metadata_file):
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    section_structure = json.load(f)
                    self.logger.info(f"å·²åŠ è½½sectionç»“æ„: {len(section_structure.get('sections', []))} sections")
                    return section_structure

            # å›é€€åˆ°PDFç›®å½•
            fallback_file = os.path.join(self.pdf_dir, 'sectionStructure.json')
            if os.path.exists(fallback_file):
                with open(fallback_file, 'r', encoding='utf-8') as f:
                    section_structure = json.load(f)
                    self.logger.info(f"å·²åŠ è½½sectionç»“æ„ï¼ˆä»PDFç›®å½•ï¼‰: {len(section_structure.get('sections', []))} sections")
                    return section_structure

        except Exception as e:
            self.logger.debug(f"åŠ è½½sectionç»“æ„å¤±è´¥ï¼ˆå°†ä½¿ç”¨flat TOCï¼‰: {e}")

        return section_structure

    def _get_pdf_files(self, directory_path: str, engine_filter: str = None) -> List[str]:
        """
        è·å–ç›®å½•ä¸­çš„PDFæ–‡ä»¶åˆ—è¡¨ï¼ˆæ™ºèƒ½æ’åºï¼‰

        æ”¯æŒï¼š
        1. æ•°å­—å‰ç¼€æ–‡ä»¶ï¼ˆ000-xxx.pdf, 001-xxx.pdfï¼‰- æŒ‰æ•°å­—æ’åº
        2. å“ˆå¸Œå‰ç¼€æ–‡ä»¶ï¼ˆ676cb9dd-xxx.pdfï¼‰- æŒ‰æ–‡ä»¶åˆ›å»ºæ—¶é—´æ’åº
        3. æ··åˆæƒ…å†µ - æ•°å­—æ–‡ä»¶ä¼˜å…ˆï¼Œç„¶åå“ˆå¸Œæ–‡ä»¶
        4. å¼•æ“è¿‡æ»¤ï¼šåªè·å–ç‰¹å®šå¼•æ“ç”Ÿæˆçš„PDFæ–‡ä»¶

        Args:
            directory_path: ç›®å½•è·¯å¾„
            engine_filter: å¼•æ“è¿‡æ»¤å™¨ï¼Œå¯é€‰å€¼ï¼š'puppeteer', None(æ‰€æœ‰æ–‡ä»¶)
        """
        try:
            if not os.path.exists(directory_path):
                return []

            all_files = os.listdir(directory_path)
            self.logger.debug(f"ç›®å½• {directory_path} ä¸­çš„æ‰€æœ‰æ–‡ä»¶: {all_files}")

            files = [
                f for f in all_files
                if f.endswith('.pdf') and os.path.isfile(os.path.join(directory_path, f))
            ]

            # æ ¹æ®å¼•æ“è¿‡æ»¤PDFæ–‡ä»¶
            if engine_filter:
                if engine_filter == 'puppeteer':
                    # åªè¦åŒ…å«_puppeteerçš„æ–‡ä»¶
                    files = [f for f in files if '_puppeteer.pdf' in f]
                elif engine_filter == 'single':
                    # åªè¦ä¸åŒ…å«_puppeteerçš„æ–‡ä»¶ï¼ˆå•å¼•æ“æ¨¡å¼çš„æ–‡ä»¶ï¼‰
                    files = [f for f in files if '_puppeteer.pdf' not in f]

            if not files:
                return []

            self.logger.debug(f"è¿‡æ»¤åçš„PDFæ–‡ä»¶ (engine_filter={engine_filter}): {files}")

            # ğŸ”¥ æ™ºèƒ½æ’åºé€»è¾‘ï¼šæ”¯æŒæ•°å­—å‰ç¼€å’Œå“ˆå¸Œå‰ç¼€
            def get_sort_key(filename: str) -> tuple:
                try:
                    # å¯¹äºåŒå¼•æ“æ–‡ä»¶ï¼Œéœ€è¦å»æ‰_puppeteeråç¼€æ¥è·å–å‰ç¼€
                    name_for_sorting = filename
                    if '_puppeteer.pdf' in filename:
                        name_for_sorting = filename.replace('_puppeteer.pdf', '.pdf')

                    parts = name_for_sorting.split('-', 1)  # åªåˆ†å‰²ç¬¬ä¸€ä¸ªè¿å­—ç¬¦
                    if len(parts) == 0:
                        return (999999, 0, filename)

                    prefix = parts[0]

                    # æ£€æŸ¥æ˜¯å¦ä¸ºæ•°å­—å‰ç¼€ï¼ˆåŒ…æ‹¬è¡¥é›¶çš„æƒ…å†µï¼‰
                    if prefix.isdigit():
                        # æ•°å­—å‰ç¼€ï¼ŒæŒ‰æ•°å­—å¤§å°æ’åºï¼Œä¼˜å…ˆçº§æœ€é«˜
                        return (0, int(prefix), filename)

                    # æ£€æŸ¥æ˜¯å¦ä¸ºè¡¥é›¶çš„æ•°å­—å‰ç¼€ï¼ˆå¦‚ 001, 002ï¼‰
                    try:
                        # å»æ‰å‰å¯¼é›¶ï¼Œä½†ä¿ç•™è‡³å°‘ä¸€ä¸ª0
                        num = int(prefix.lstrip('0') or '0')
                        if prefix.startswith('0') and len(prefix) > 1:
                            # è¿™æ˜¯è¡¥é›¶çš„æ•°å­—ï¼Œä¼˜å…ˆçº§æœ€é«˜
                            return (0, num, filename)
                    except ValueError:
                        pass

                    # æ£€æŸ¥æ˜¯å¦ä¸ºå“ˆå¸Œå‰ç¼€ï¼ˆ8ä½åå…­è¿›åˆ¶ï¼‰
                    if len(prefix) == 8 and all(c in '0123456789abcdef' for c in prefix.lower()):
                        # å“ˆå¸Œå‰ç¼€ï¼ŒæŒ‰æ–‡ä»¶åˆ›å»ºæ—¶é—´æ’åºï¼Œä¼˜å…ˆçº§æ¬¡é«˜
                        try:
                            file_path = os.path.join(directory_path, filename)
                            mtime = os.path.getmtime(file_path)
                            return (1, mtime, filename)
                        except:
                            return (1, 0, filename)

                    # å…¶ä»–æƒ…å†µï¼ŒæŒ‰æ–‡ä»¶åå­—æ¯æ’åºï¼Œä¼˜å…ˆçº§æœ€ä½
                    return (2, 0, filename)

                except Exception as e:
                    self.logger.debug(f"æ’åºé”®ç”Ÿæˆå¤±è´¥ {filename}: {e}")
                    return (999999, 0, filename)

            # æŒ‰æ’åºé”®æ’åº
            files.sort(key=get_sort_key)

            # ç»Ÿè®¡ä¸åŒç±»å‹çš„æ–‡ä»¶
            numeric_files = []
            hash_files = []
            other_files = []

            for f in files:
                # å¯¹äºåŒå¼•æ“æ–‡ä»¶ï¼Œéœ€è¦å»æ‰å¼•æ“åç¼€æ¥è·å–å‰ç¼€
                name_for_analysis = f
                if '_puppeteer.pdf' in f:
                    name_for_analysis = f.replace('_puppeteer.pdf', '.pdf')

                prefix = name_for_analysis.split('-')[0] if '-' in name_for_analysis else ''
                if prefix.isdigit() or (prefix.startswith('0') and prefix.isdigit()):
                    numeric_files.append(f)
                elif len(prefix) == 8 and all(c in '0123456789abcdef' for c in prefix.lower()):
                    hash_files.append(f)
                else:
                    other_files.append(f)

            # Only log if there are significant numbers of files
            if len(files) > 10:
                engine_info = f" ({engine_filter} engine)" if engine_filter else ""
                self.logger.info(f"Found {len(files)} PDF files in {directory_path}{engine_info}")

            self.logger.debug(f"æ’åºåæ–‡ä»¶åˆ—è¡¨å‰5ä¸ª: {files[:5]}")
            return files

        except Exception as e:
            self.logger.error(f"è·å–PDFæ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return []

    def _create_bookmark_title(self, filename: str, article_titles: Dict[str, str]) -> str:
        """
        åˆ›å»ºä¹¦ç­¾æ ‡é¢˜ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        
        ğŸ”§ ä¿®å¤ï¼šæ­£ç¡®å¤„ç†å¼•æ“åç¼€ï¼Œé¿å…æ ‡é¢˜ä¸­å‡ºç°"Puppeteer"

        ä¼˜å…ˆçº§ï¼š
        1. æ–‡ç« æ ‡é¢˜æ˜ å°„
        2. æ¸…ç†åçš„æ–‡ä»¶åï¼ˆç§»é™¤å¼•æ“åç¼€ï¼‰
        
        æ”¯æŒçš„æ–‡ä»¶åæ ¼å¼ï¼š
        - 001-page-name.pdf â†’ "Page Name"
        - 001-page-name_puppeteer.pdf â†’ "Page Name" (ç§»é™¤å¼•æ“åç¼€)
        - 001-page-name_puppeteer.pdf â†’ "Page Name" (ç§»é™¤å¼•æ“åç¼€)
        """
        try:
            self.logger.debug(f"ä¸ºæ–‡ä»¶åˆ›å»ºä¹¦ç­¾æ ‡é¢˜: {filename}")

            # ğŸ”¥ é¦–å…ˆç§»é™¤å¼•æ“åç¼€ï¼ˆ_puppeteerï¼‰
            cleaned_filename = filename
            if '_puppeteer.pdf' in filename:
                cleaned_filename = filename.replace('_puppeteer.pdf', '.pdf')
                self.logger.debug(f"ç§»é™¤Puppeteerå¼•æ“åç¼€: {filename} -> {cleaned_filename}")

            # æå–å‰ç¼€å’Œæ–‡ä»¶åéƒ¨åˆ†
            parts = cleaned_filename.split('-', 1)  # åªåˆ†å‰²ç¬¬ä¸€ä¸ªè¿å­—ç¬¦
            if len(parts) < 2:
                title = os.path.splitext(cleaned_filename)[0]
                self.logger.debug(f"æ— å‰ç¼€æ–‡ä»¶ï¼Œä½¿ç”¨æ–‡ä»¶åä½œä¸ºæ ‡é¢˜: {title}")
                return title

            prefix = parts[0]
            name_part = parts[1]

            # ğŸ”¥ å°è¯•ä»æ–‡ç« æ ‡é¢˜æ˜ å°„ä¸­æŸ¥æ‰¾
            # æ”¯æŒæ•°å­—å‰ç¼€ï¼ˆåŒ…æ‹¬è¡¥é›¶ï¼‰å’ŒåŸå§‹å‰ç¼€
            possible_keys = [prefix]

            # å¦‚æœæ˜¯æ•°å­—å‰ç¼€ï¼Œæ·»åŠ å¤šç§å¯èƒ½çš„é”®æ ¼å¼
            if prefix.isdigit():
                num = int(prefix)
                possible_keys.extend([
                    str(num),                    # å»æ‰å‰å¯¼é›¶: "1"
                    str(num).zfill(3),          # 3ä½è¡¥é›¶: "001"
                    str(num).zfill(2)           # 2ä½è¡¥é›¶: "01"
                ])

            # æŸ¥æ‰¾æ ‡é¢˜æ˜ å°„
            for key in possible_keys:
                if key in article_titles:
                    title = article_titles[key]
                    self.logger.debug(f"æ‰¾åˆ°æ–‡ç« æ ‡é¢˜æ˜ å°„ {key}: {title}")
                    return title

            # å¦‚æœæ²¡æ‰¾åˆ°æ˜ å°„ï¼Œä½¿ç”¨æ¸…ç†åçš„æ–‡ä»¶å
            cleaned_name = os.path.splitext(name_part)[0]
            # å°†è¿å­—ç¬¦å’Œä¸‹åˆ’çº¿æ›¿æ¢ä¸ºç©ºæ ¼ï¼Œä½¿ç”¨æ ‡é¢˜æ ¼å¼
            title = cleaned_name.replace('-', ' ').replace('_', ' ')
            # è½¬æ¢ä¸ºæ ‡é¢˜æ ¼å¼ï¼šæ¯ä¸ªå•è¯é¦–å­—æ¯å¤§å†™
            title = ' '.join(word.capitalize() for word in title.split())

            self.logger.debug(f"ä½¿ç”¨æ¸…ç†åçš„æ–‡ä»¶åä½œä¸ºæ ‡é¢˜: {title}")
            return title

        except Exception as e:
            self.logger.warning(f"åˆ›å»ºä¹¦ç­¾æ ‡é¢˜å¤±è´¥ {filename}: {e}")
            return os.path.splitext(filename)[0]

    def _build_hierarchical_toc(
        self,
        files: List[str],
        page_counts: Dict[str, int],
        file_to_index: Dict[str, str]
    ) -> List[List[Any]]:
        """
        æ„å»ºåˆ†å±‚TOCç»“æ„

        Args:
            files: PDFæ–‡ä»¶ååˆ—è¡¨ï¼ˆæŒ‰åˆå¹¶é¡ºåºï¼‰
            page_counts: æ–‡ä»¶å -> é¡µæ•°æ˜ å°„
            file_to_index: æ–‡ä»¶å -> ç´¢å¼•æ˜ å°„

        Returns:
            åˆ†å±‚TOCåˆ—è¡¨ [[level, title, page, link], ...]
        """
        toc = []

        if not self.section_structure or 'sections' not in self.section_structure:
            # Fallbackåˆ°flat TOC
            self.logger.debug("æ²¡æœ‰sectionç»“æ„ï¼Œä½¿ç”¨flat TOC")
            return None

        sections = self.section_structure['sections']
        current_page = 0

        # æ„å»ºæ–‡ä»¶ååˆ°é¡µæ•°çš„æ˜ å°„
        file_page_map = {}  # filename -> start_page
        for filename in files:
            file_page_map[filename] = current_page
            current_page += page_counts.get(filename, 0)

        # ğŸ”¥ æ€§èƒ½ä¼˜åŒ–ï¼šé¢„å…ˆæ„å»ºåå‘ç´¢å¼• (index -> filename) ä»¥é¿å…O(nÂ²)åµŒå¥—å¾ªç¯
        index_to_file = {}  # index -> filename
        for filename in files:
            file_index = file_to_index.get(filename)
            if file_index:
                index_to_file[file_index] = filename

        self.logger.debug(f"æ„å»ºç´¢å¼•æ˜ å°„: {len(index_to_file)} ä¸ªæ–‡ä»¶")

        # éå†æ¯ä¸ªsection
        for section in sections:
            section_title = section.get('title', 'Untitled Section')
            section_pages = section.get('pages', [])

            if not section_pages:
                # è·³è¿‡ç©ºsection
                continue

            # æ‰¾åˆ°è¯¥sectionçš„ç¬¬ä¸€ä¸ªæœ‰æ•ˆé¡µé¢ä½œä¸ºsectioné“¾æ¥ç›®æ ‡
            section_start_page = None
            valid_pages = []

            for page_info in section_pages:
                page_index = page_info.get('index')
                if not page_index:
                    continue

                # ğŸ”¥ O(1) æŸ¥æ‰¾è€Œä¸æ˜¯O(n)åµŒå¥—å¾ªç¯
                found_file = index_to_file.get(page_index)

                if found_file and found_file in file_page_map:
                    page_start = file_page_map[found_file]
                    page_title = self.article_titles.get(page_index, f"Page {page_index}")

                    if section_start_page is None:
                        section_start_page = page_start

                    valid_pages.append({
                        'title': page_title,
                        'page': page_start,
                        'index': page_index
                    })

            # å¦‚æœè¯¥sectionæœ‰æœ‰æ•ˆé¡µé¢ï¼Œæ·»åŠ åˆ°TOC
            if valid_pages:
                # æ·»åŠ sectionæ ‡é¢˜ï¼ˆlevel 1ï¼‰
                toc.append([
                    1,  # Level 1: Section
                    section_title,
                    section_start_page + 1,  # PyMuPDFé¡µç ä»1å¼€å§‹
                    {"kind": 1, "page": section_start_page}
                ])

                # æ·»åŠ è¯¥sectionä¸‹çš„é¡µé¢ï¼ˆlevel 2ï¼‰
                for page in valid_pages:
                    toc.append([
                        2,  # Level 2: Page
                        page['title'],
                        page['page'] + 1,
                        {"kind": 1, "page": page['page']}
                    ])

        self.logger.info(f"æ„å»ºäº†åˆ†å±‚TOC: {len([t for t in toc if t[0] == 1])} sections, {len([t for t in toc if t[0] == 2])} pages")
        return toc

    def _monitor_memory(self) -> None:
        """ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        try:
            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            self.stats['memory_peak'] = max(self.stats['memory_peak'], memory_mb)

            # å¦‚æœå†…å­˜ä½¿ç”¨è¶…è¿‡é˜ˆå€¼ï¼Œå¼ºåˆ¶åƒåœ¾å›æ”¶
            if memory_mb > 500:  # 500MBé˜ˆå€¼
                gc.collect()
                self.logger.debug(f"å†…å­˜ä½¿ç”¨: {memory_mb:.1f}MB, å·²æ‰§è¡Œåƒåœ¾å›æ”¶")
        except Exception:
            pass  # å†…å­˜ç›‘æ§å¤±è´¥ä¸åº”å½±å“ä¸»æµç¨‹

    def _generate_friendly_filename(self, directory_name: str, current_date: str) -> str:
        """
        ç”Ÿæˆç”¨æˆ·å‹å¥½çš„PDFæ–‡ä»¶å
        
        è½¬æ¢è§„åˆ™ï¼š
        - docs.anthropic.com-docs -> Claude-Code-Docs
        - github.com-docs -> GitHub-Docs  
        - example.com-api -> Example-API
        """
        try:
            # ç§»é™¤å¸¸è§çš„åŸŸååç¼€å’Œå‰ç¼€
            clean_name = directory_name
            
            # å¤„ç† docs.anthropic.com-docs æ ¼å¼
            if 'anthropic.com' in clean_name:
                clean_name = 'Claude-Code-Docs'
            elif 'github.com' in clean_name:
                clean_name = 'GitHub-Docs'
            else:
                # é€šç”¨å¤„ç†ï¼šç§»é™¤åŸŸåéƒ¨åˆ†ï¼Œåªä¿ç•™å†…å®¹ç±»å‹
                if '-' in clean_name:
                    parts = clean_name.split('-')
                    # å–æœ€åä¸€éƒ¨åˆ†ä½œä¸ºå†…å®¹ç±»å‹
                    content_type = parts[-1]
                    if '.' in parts[0]:
                        # æå–åŸŸåçš„ä¸»è¦éƒ¨åˆ†
                        domain_parts = parts[0].split('.')
                        main_domain = domain_parts[-2] if len(domain_parts) > 1 else domain_parts[0]
                        clean_name = f"{main_domain.title()}-{content_type.title()}"
                    else:
                        clean_name = content_type.title()
                else:
                    clean_name = clean_name.replace('.', '-').title()
            
            return f"{clean_name}_{current_date}.pdf"
            
        except Exception as e:
            self.logger.warning(f"æ–‡ä»¶åä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹åç§°: {e}")
            return f"{directory_name}_{current_date}.pdf"

    def merge_pdfs_stream(
        self,
        directory_path: str,
        output_path: str,
        progress_callback: Optional[Callable[[int, int], None]] = None,
        engine_filter: str = None
    ) -> bool:
        """æµå¼åˆå¹¶PDFæ–‡ä»¶"""
        try:
            files = self._get_pdf_files(directory_path, engine_filter)
            if not files:
                return False

            merged_pdf = None
            current_file_pdf = None

            try:
                # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(output_path), exist_ok=True)

                merged_pdf = fitz.open()  # åˆ›å»ºç©ºçš„PDFæ–‡æ¡£
                toc = []  # ç›®å½•ç»“æ„

                # ğŸ”¥ æ–°å¢ï¼šæ”¶é›†ä¿¡æ¯ç”¨äºæ„å»ºåˆ†å±‚TOC
                page_counts = {}  # filename -> page_count
                file_to_index = {}  # filename -> index (ç”¨äºåŒ¹é…sectionStructure)

                # Starting merge operation (logging reduced for cleaner output)

                for i, filename in enumerate(files):
                    try:
                        self.logger.debug(f"å¤„ç†æ–‡ä»¶ {i+1}/{len(files)}: {filename}")
                        file_path = os.path.join(directory_path, filename)

                        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                        if not os.path.exists(file_path):
                            self.logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                            continue

                        # æ‰“å¼€å½“å‰PDFæ–‡ä»¶
                        current_file_pdf = fitz.open(file_path)
                        page_count = current_file_pdf.page_count

                        if page_count == 0:
                            self.logger.warning(f"è·³è¿‡ç©ºPDFæ–‡ä»¶: {filename}")
                            current_file_pdf.close()
                            continue

                        # è®°å½•åˆå¹¶å‰çš„é¡µæ•°
                        start_page = merged_pdf.page_count

                        # æ’å…¥PDFé¡µé¢
                        merged_pdf.insert_pdf(current_file_pdf)

                        # ğŸ”¥ æ–°å¢ï¼šè®°å½•ä¿¡æ¯ç”¨äºåˆ†å±‚TOC
                        page_counts[filename] = page_count

                        # ä»æ–‡ä»¶åæå–ç´¢å¼•ï¼ˆæ”¯æŒ 001-xxx.pdf å’Œ 001-xxx_puppeteer.pdfï¼‰
                        cleaned_filename = filename
                        if '_puppeteer.pdf' in filename:
                            cleaned_filename = filename.replace('_puppeteer.pdf', '.pdf')

                        prefix = cleaned_filename.split('-')[0] if '-' in cleaned_filename else ''
                        if prefix.isdigit():
                            # ç§»é™¤å‰å¯¼é›¶ä»¥åŒ¹é…scraperç”Ÿæˆçš„ç´¢å¼•æ ¼å¼
                            # "001" â†’ "1", "000" â†’ "0"
                            file_to_index[filename] = str(int(prefix))

                        # åˆ›å»ºä¹¦ç­¾ï¼ˆç”¨äºflat TOC fallbackï¼‰
                        bookmark_title = self._create_bookmark_title(filename, self.article_titles)
                        toc.append([
                            1,  # çº§åˆ«
                            bookmark_title,  # æ ‡é¢˜
                            start_page + 1,  # é¡µç ï¼ˆä»1å¼€å§‹ï¼‰
                            {"kind": 1, "page": start_page}  # é“¾æ¥ä¿¡æ¯
                        ])

                        # å…³é—­å½“å‰æ–‡ä»¶
                        current_file_pdf.close()
                        current_file_pdf = None

                        # æ›´æ–°ç»Ÿè®¡
                        self.stats['files_processed'] += 1
                        self.stats['total_pages'] += page_count

                        # å†…å­˜ç›‘æ§
                        self._monitor_memory()

                        # è¿›åº¦å›è°ƒ
                        if progress_callback:
                            progress_callback(i + 1, len(files))

                        self.logger.debug(f"å·²åˆå¹¶: {filename} ({page_count} é¡µ) -> ä¹¦ç­¾: {bookmark_title}")

                    except Exception as e:
                        error_msg = f"å¤„ç†æ–‡ä»¶å¤±è´¥ {filename}: {e}"
                        self.logger.error(error_msg)
                        self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                        self.stats['errors'].append(error_msg)

                        if current_file_pdf:
                            current_file_pdf.close()
                            current_file_pdf = None

                        # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶
                        continue

                # ğŸ”¥ æ–°å¢ï¼šå°è¯•æ„å»ºåˆ†å±‚TOC
                hierarchical_toc = None
                if self.section_structure:
                    try:
                        hierarchical_toc = self._build_hierarchical_toc(files, page_counts, file_to_index)
                        if hierarchical_toc:
                            self.logger.info(f"ä½¿ç”¨åˆ†å±‚TOCç»“æ„")
                            toc = hierarchical_toc
                        else:
                            self.logger.info(f"ä½¿ç”¨flat TOCç»“æ„ï¼ˆæ— sectionä¿¡æ¯ï¼‰")
                    except Exception as e:
                        self.logger.warning(f"æ„å»ºåˆ†å±‚TOCå¤±è´¥ï¼Œä½¿ç”¨flat TOC: {e}")
                        # tocå·²ç»åŒ…å«flatç»“æ„ï¼Œæ— éœ€ä¿®æ”¹

                # è®¾ç½®ç›®å½•ç»“æ„ï¼ˆå¦‚æœå¯ç”¨äº†ä¹¦ç­¾åŠŸèƒ½ï¼‰
                bookmarks_enabled = self.config.get('pdf', {}).get('bookmarks', True)
                if bookmarks_enabled and toc:
                    merged_pdf.set_toc(toc)
                    self.logger.info(f"å·²åˆ›å»ºPDFç›®å½•ï¼ŒåŒ…å« {len(toc)} ä¸ªä¹¦ç­¾")
                elif not bookmarks_enabled:
                    self.logger.info("ä¹¦ç­¾åŠŸèƒ½å·²ç¦ç”¨ï¼Œè·³è¿‡ç›®å½•åˆ›å»º")

                # ä¿å­˜åˆå¹¶åçš„PDF
                merged_pdf.save(output_path)

                return True

            except Exception as e:
                error_msg = f"PDFåˆå¹¶å¤±è´¥: {e}"
                self.logger.error(error_msg)
                self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                self.stats['errors'].append(error_msg)
                raise FileProcessingError(error_msg)

            finally:
                # æ¸…ç†èµ„æº
                if current_file_pdf:
                    current_file_pdf.close()
                if merged_pdf:
                    merged_pdf.close()

                # å¼ºåˆ¶åƒåœ¾å›æ”¶
                gc.collect()

        except Exception as e:
            self.logger.error(f"merge_pdfs_stream æ‰§è¡Œå¤±è´¥: {e}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return False

    def _detect_dual_engine_mode(self, directory_path: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºåŒå¼•æ“æ¨¡å¼ï¼ˆå·²å¼ƒç”¨ï¼Œç°åœ¨åªæ”¯æŒPuppeteerï¼‰"""
        # åŒå¼•æ“æ¨¡å¼å·²ç§»é™¤ï¼Œå§‹ç»ˆè¿”å›False
        return False

    def merge_directory(self, directory_name: Optional[str] = None) -> List[str]:
        """åˆå¹¶æŒ‡å®šç›®å½•æˆ–æ‰€æœ‰å­ç›®å½•çš„PDFæ–‡ä»¶"""
        try:
            if not os.path.exists(self.pdf_dir):
                raise FileProcessingError(f"PDFç›®å½•ä¸å­˜åœ¨: {self.pdf_dir}")

            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(self.final_pdf_dir, exist_ok=True)

            # è·å–åŸŸåå’Œæ—¶é—´æˆ³ï¼ˆåŒ…å«ç§’ï¼‰
            url = urlparse(self.config['rootURL'])
            domain = url.hostname.replace('.', '_') if url.hostname else 'unknown'
            current_date = datetime.now().strftime('%Y%m%d_%H%M%S')

            merged_files = []

            if directory_name:
                # åˆå¹¶æŒ‡å®šç›®å½•
                directory_path = os.path.join(self.pdf_dir, directory_name)
                if os.path.isdir(directory_path):
                    # å•å¼•æ“æ¨¡å¼ï¼šæ­£å¸¸åˆå¹¶
                    friendly_filename = self._generate_friendly_filename(directory_name, current_date)
                    output_path = os.path.join(
                        self.final_pdf_dir,
                        friendly_filename
                    )
                    if self.merge_pdfs_stream(directory_path, output_path):
                        merged_files.append(output_path)
                else:
                    self.logger.warning(f"æŒ‡å®šç›®å½•ä¸å­˜åœ¨: {directory_path}")
            else:
                # é¦–å…ˆåˆå¹¶æ ¹ç›®å½•
                # å•å¼•æ“æ¨¡å¼ï¼šæ­£å¸¸åˆå¹¶
                root_output_path = os.path.join(
                    self.final_pdf_dir,
                    f"{domain}_{current_date}.pdf"
                )
                if self.merge_pdfs_stream(self.pdf_dir, root_output_path):
                    merged_files.append(root_output_path)

                # ç„¶ååˆå¹¶æ‰€æœ‰å­ç›®å½•
                try:
                    items = os.listdir(self.pdf_dir)
                    self.logger.debug(f"PDFç›®å½•ä¸­çš„æ‰€æœ‰é¡¹ç›®: {items}")

                    for item in items:
                        try:
                            item_path = os.path.join(self.pdf_dir, item)

                            # è·³è¿‡éç›®å½•å’Œç‰¹æ®Šç›®å½•
                            if not os.path.isdir(item_path) or item in ['finalPdf', 'metadata', '.temp']:
                                self.logger.debug(f"è·³è¿‡é¡¹ç›®: {item} (éç›®å½•æˆ–ç‰¹æ®Šç›®å½•)")
                                continue

                            pass  # Processing subdirectory silently
                            
                            # å•å¼•æ“æ¨¡å¼ï¼šæ­£å¸¸åˆå¹¶
                            output_path = os.path.join(
                                self.final_pdf_dir,
                                f"{item}_{current_date}.pdf"
                            )
                            if self.merge_pdfs_stream(item_path, output_path):
                                merged_files.append(output_path)

                        except Exception as e:
                            self.logger.error(f"å¤„ç†å­ç›®å½• {item} æ—¶å‡ºé”™: {e}")
                            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                            continue

                except Exception as e:
                    self.logger.error(f"åˆ—å‡ºPDFç›®å½•å†…å®¹æ—¶å‡ºé”™: {e}")
                    self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

            return merged_files

        except Exception as e:
            error_msg = f"ç›®å½•åˆå¹¶å¤±è´¥: {e}"
            self.logger.error(error_msg)
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            raise FileProcessingError(error_msg)

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–åˆå¹¶ç»Ÿè®¡ä¿¡æ¯"""
        elapsed_time = 0
        if self.stats['start_time']:
            elapsed_time = time.time() - self.stats['start_time']

        return {
            'files_processed': self.stats['files_processed'],
            'total_pages': self.stats['total_pages'],
            'elapsed_time': elapsed_time,
            'memory_peak_mb': self.stats['memory_peak'],
            'errors_count': len(self.stats['errors']),
            'errors': self.stats['errors'][-10:],  # æœ€è¿‘10ä¸ªé”™è¯¯
            'avg_pages_per_file': (
                self.stats['total_pages'] / self.stats['files_processed']
                if self.stats['files_processed'] > 0 else 0
            ),
            'processing_speed': (
                self.stats['files_processed'] / elapsed_time
                if elapsed_time > 0 else 0
            )
        }

    def run(self) -> Dict[str, Any]:
        """è¿è¡ŒPDFåˆå¹¶ä»»åŠ¡"""
        self.stats['start_time'] = time.time()

        try:
            # æ‰§è¡Œåˆå¹¶
            merged_files = self.merge_directory()

            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = self.get_statistics()

            result = {
                'success': True,
                'merged_files': merged_files,
                'statistics': stats
            }

            # Task completed successfully (detailed stats printed separately)

            return result

        except Exception as e:
            error_msg = f"PDFåˆå¹¶ä»»åŠ¡å¤±è´¥: {e}"
            self.logger.error(error_msg)
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

            return {
                'success': False,
                'error': error_msg,
                'statistics': self.get_statistics()
            }

def main():
    """ä¸»å‡½æ•°ï¼Œæ”¯æŒå‘½ä»¤è¡Œæ‰§è¡Œ"""
    import sys
    import argparse

    parser = argparse.ArgumentParser(description='Smart PDF Merger Tool')
    parser.add_argument('--config', default='config.json', help='Configuration file path')
    parser.add_argument('--directory', help='Specify directory name to merge')
    parser.add_argument('--verbose', '-v', action='store_true', help='Verbose output')

    args = parser.parse_args()

    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.basicConfig(level=logging.INFO)
    else:
        logging.basicConfig(level=logging.WARNING)

    try:
        # åˆ›å»ºPDFåˆå¹¶å™¨
        merger = PDFMerger(config_path=args.config)

        # æ‰§è¡Œåˆå¹¶
        if args.directory:
            merged_files = merger.merge_directory(args.directory)
        else:
            result = merger.run()
            merged_files = result.get('merged_files', [])

        # Output results  
        print(f"\nâœ… Merge completed! Generated {len(merged_files)} PDF file(s):")
        for file_path in merged_files:
            print(f"  ğŸ“„ {file_path}")

        # Output statistics
        stats = merger.get_statistics()
        print(f"\nğŸ“Š Statistics:")
        print(f"  - Files processed: {stats['files_processed']}")
        print(f"  - Total pages: {stats['total_pages']}")
        print(f"  - Duration: {stats['elapsed_time']:.1f} seconds")
        print(f"  - Memory peak: {stats['memory_peak_mb']:.1f} MB")

        if stats['errors_count'] > 0:
            print(f"  âš ï¸  Errors: {stats['errors_count']}")

        return 0

    except Exception as e:
        print(f"âŒ Execution failed: {e}", file=sys.stderr)
        print(f"Error details: {traceback.format_exc()}", file=sys.stderr)
        return 1

if __name__ == '__main__':
    sys.exit(main())
